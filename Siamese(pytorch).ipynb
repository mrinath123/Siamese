{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits(n_class=2, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data=digits.data/16.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "355        0.0        0.0     0.0625       0.75     0.6250     0.1875   \n",
       "356        0.0        0.0     0.5000       0.75     0.6875     0.3750   \n",
       "357        0.0        0.0     0.3125       1.00     0.6250     0.0000   \n",
       "358        0.0        0.0     0.3750       0.75     0.7500     0.3750   \n",
       "359        0.0        0.0     0.3750       1.00     0.8125     0.6875   \n",
       "\n",
       "     pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "355     0.0000        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "356     0.0000        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "357     0.0000        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "358     0.0000        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "359     0.0625        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "     pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "355        0.0     0.0625     0.4375      0.750     0.6250     0.0000   \n",
       "356        0.0     0.2500     0.6875      0.750     0.4375     0.0000   \n",
       "357        0.0     0.2500     0.9375      1.000     0.5000     0.0625   \n",
       "358        0.0     0.1250     0.6875      0.625     0.2500     0.0000   \n",
       "359        0.0     0.3750     1.0000      0.875     0.3750     0.0000   \n",
       "\n",
       "     pixel_7_7  target  \n",
       "355        0.0       1  \n",
       "356        0.0       1  \n",
       "357        0.0       0  \n",
       "358        0.0       1  \n",
       "359        0.0       0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=digits.data.iloc[200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu=digits.target.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data['target']=uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.asarray(digits.data.iloc[1,:-1])\n",
    "x=x.reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1afe1ce9358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamdata(Dataset):\n",
    "    def __init__(self,train_df):\n",
    "        self.train_df=train_df\n",
    "      \n",
    "    def __len__(self):\n",
    "        return(len(self.train_df))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        i=random.randint(0,359)\n",
    "        j=random.randint(0,359)\n",
    "        img1=self.train_df.iloc[i,:]\n",
    "        img2=self.train_df.iloc[j,:]\n",
    "        \n",
    "                                \n",
    "        IMG1=img1.iloc[0:-1]\n",
    "        IMG2=img2.iloc[0:-1]\n",
    "        IMG1=np.array([IMG1])\n",
    "        IMG2=np.array([IMG2])\n",
    "        IMG1 = IMG1.astype('float')\n",
    "        IMG2 = IMG2.astype('float')\n",
    "                         \n",
    "        return  IMG1,IMG2,torch.from_numpy(np.array([img1['target']==img2['target']],dtype=np.float32))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if same image return 1\n",
    "else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.0000, 0.0000, 0.3125, 0.7500, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.8750, 0.6250, 0.8750, 0.7500, 0.0000, 0.0000,\n",
       "           0.0000, 0.1250, 1.0000, 1.0000, 0.5000, 0.6875, 0.1250, 0.0000,\n",
       "           0.0000, 0.1875, 1.0000, 0.6875, 0.0000, 0.5625, 0.1875, 0.0000,\n",
       "           0.0000, 0.3125, 0.7500, 0.1250, 0.0000, 0.7500, 0.2500, 0.0000,\n",
       "           0.0000, 0.0625, 0.7500, 0.0000, 0.0000, 0.8125, 0.1875, 0.0000,\n",
       "           0.0000, 0.0000, 0.8125, 0.3750, 0.5000, 0.8125, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1875, 0.8750, 0.7500, 0.1875, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[[0.0000, 0.0000, 0.0625, 0.9375, 0.9375, 0.1250, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.7500, 1.0000, 0.4375, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.8750, 1.0000, 0.3125, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.8125, 1.0000, 0.1250, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1250, 1.0000, 0.8125, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3750, 1.0000, 0.8125, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3750, 1.0000, 0.6875, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0625, 0.8750, 1.0000, 0.4375, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[0.]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=Siamdata(digits.data)\n",
    "\n",
    "vis_dataloader = DataLoader(data,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Siamodel(\n",
       "  (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Siamodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(64,16)\n",
    "        self.fc2=nn.Linear(16,8)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "        \n",
    "model = Siamodel()\n",
    "model        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=Siamodel()\n",
    "        self.fc1 = nn.Linear(8,1)\n",
    "    def forward(self,x1,x2):\n",
    "        vec1=self.model(x1)\n",
    "        vec2=self.model(x2)\n",
    "        feat=torch.abs(torch.add(vec1,-vec2,alpha=1))\n",
    "        feat=self.fc1(feat)              \n",
    "        p=F.sigmoid(feat)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Siamese(\n",
       "  (model): Siamodel(\n",
       "    (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Siamese()\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(data,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=model1.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6716541359821956\n",
      "Training loss: 0.6439513797561328\n",
      "Training loss: 0.6073124101592435\n",
      "Training loss: 0.5201237010045184\n",
      "Training loss: 0.4251297257426712\n",
      "Training loss: 0.3519780771496395\n",
      "Training loss: 0.3236306125919024\n",
      "Training loss: 0.2577373212720785\n",
      "Training loss: 0.2500615296885371\n",
      "Training loss: 0.21210288017367324\n",
      "Training loss: 0.1991351573728025\n",
      "Training loss: 0.1663628040631819\n",
      "Training loss: 0.16683346522558068\n",
      "Training loss: 0.15609791161647688\n",
      "Training loss: 0.1469052106038564\n",
      "Training loss: 0.14204560770239266\n",
      "Training loss: 0.12735689992809462\n",
      "Training loss: 0.11398752469879886\n",
      "Training loss: 0.10777348400507536\n",
      "Training loss: 0.09341981697491267\n",
      "Training loss: 0.10116755246158896\n",
      "Training loss: 0.08718749591563311\n",
      "Training loss: 0.08958140424478592\n",
      "Training loss: 0.07966299410133312\n",
      "Training loss: 0.07296807076781989\n",
      "Training loss: 0.07647511704255723\n",
      "Training loss: 0.06831840440863743\n",
      "Training loss: 0.07257129262887045\n",
      "Training loss: 0.07091297320762856\n",
      "Training loss: 0.0605567958076588\n",
      "Training loss: 0.05592094538992064\n",
      "Training loss: 0.05944301311780388\n",
      "Training loss: 0.05911135347042647\n",
      "Training loss: 0.05937005495587881\n",
      "Training loss: 0.04680146537785832\n",
      "Training loss: 0.048151279157415655\n",
      "Training loss: 0.048728927375567666\n",
      "Training loss: 0.04401159606835184\n",
      "Training loss: 0.04324634980035221\n",
      "Training loss: 0.04463016165795529\n",
      "Training loss: 0.04347032509976998\n",
      "Training loss: 0.04024124987125914\n",
      "Training loss: 0.039864062949911586\n",
      "Training loss: 0.04073711113952514\n",
      "Training loss: 0.039415300213214426\n",
      "Training loss: 0.034966925502521916\n",
      "Training loss: 0.03281225394263553\n",
      "Training loss: 0.03777253963829329\n",
      "Training loss: 0.034647674305920695\n",
      "Training loss: 0.032969567749791574\n",
      "Training loss: 0.030098253245038602\n",
      "Training loss: 0.033455329144554624\n",
      "Training loss: 0.03154720313226183\n",
      "Training loss: 0.03180304023715305\n",
      "Training loss: 0.028135124010603047\n",
      "Training loss: 0.028721423056817408\n",
      "Training loss: 0.025344423339508163\n",
      "Training loss: 0.025902451452081247\n",
      "Training loss: 0.02817868649144657\n",
      "Training loss: 0.026063076764694416\n",
      "Training loss: 0.026124628216105825\n",
      "Training loss: 0.02314816946778188\n",
      "Training loss: 0.027342255381518042\n",
      "Training loss: 0.023550271691055967\n",
      "Training loss: 0.027751232774527228\n",
      "Training loss: 0.02086519641193768\n",
      "Training loss: 0.019274795928019253\n",
      "Training loss: 0.02236834216795008\n",
      "Training loss: 0.02152786738168086\n",
      "Training loss: 0.02020394981647971\n",
      "Training loss: 0.020004301411972847\n",
      "Training loss: 0.021729300766633566\n",
      "Training loss: 0.018923776871330726\n",
      "Training loss: 0.020227129270238543\n",
      "Training loss: 0.018916347313724043\n",
      "Training loss: 0.017525863171774996\n",
      "Training loss: 0.016751042893641474\n",
      "Training loss: 0.020311034360363717\n",
      "Training loss: 0.01917656497049999\n",
      "Training loss: 0.01889232575033222\n",
      "Training loss: 0.021215267395988727\n",
      "Training loss: 0.018361830149984194\n",
      "Training loss: 0.017429851543177697\n",
      "Training loss: 0.017306379925705388\n",
      "Training loss: 0.014940630441156424\n",
      "Training loss: 0.017511305310957445\n",
      "Training loss: 0.01578977959110893\n",
      "Training loss: 0.015266846303064893\n",
      "Training loss: 0.014181736157883682\n",
      "Training loss: 0.015230286728021585\n",
      "Training loss: 0.015676420340363015\n",
      "Training loss: 0.014959122651069063\n",
      "Training loss: 0.013944235828562846\n",
      "Training loss: 0.01406356619926454\n",
      "Training loss: 0.015386072337989592\n",
      "Training loss: 0.016211781104761434\n",
      "Training loss: 0.015213375901253635\n",
      "Training loss: 0.012986728717320754\n",
      "Training loss: 0.01319558523383522\n",
      "Training loss: 0.014178236057826627\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    run_loss=0\n",
    "    for image1,image2,labels in vis_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model1(image1.float(),image2.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        run_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {run_loss/len(vis_dataloader)}\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "\n",
    "dataiter = iter(vis_dataloader)\n",
    "image1,image2,labels = dataiter.next()\n",
    "\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model1.forward(image1.float(),image2.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9710]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.5625, 0.9375, 0.3750, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3125, 0.9375, 1.0000, 0.9375, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.9375, 0.9375, 0.2500, 1.0000, 0.1875, 0.0000,\n",
       "           0.0000, 0.1250, 0.8750, 0.3125, 0.0000, 0.7500, 0.5000, 0.0000,\n",
       "           0.0000, 0.3750, 0.8125, 0.0000, 0.0625, 0.8750, 0.3750, 0.0000,\n",
       "           0.0000, 0.0625, 0.6250, 0.8750, 0.9375, 1.0000, 0.1875, 0.0000,\n",
       "           0.0000, 0.0000, 0.1875, 1.0000, 1.0000, 0.8750, 0.0625, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5625, 0.8125, 0.3125, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[[0.0000, 0.0000, 0.4375, 0.8125, 0.5000, 0.2500, 0.0000, 0.0000,\n",
       "           0.0000, 0.0625, 0.9375, 0.6875, 0.5625, 0.9375, 0.1250, 0.0000,\n",
       "           0.0000, 0.2500, 1.0000, 0.3750, 0.0000, 0.5000, 0.4375, 0.0000,\n",
       "           0.0000, 0.2500, 0.6250, 0.0000, 0.0000, 0.4375, 0.5000, 0.0000,\n",
       "           0.0000, 0.2500, 0.6250, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000,\n",
       "           0.0000, 0.3125, 0.7500, 0.0000, 0.0000, 0.7500, 0.3125, 0.0000,\n",
       "           0.0000, 0.1875, 0.9375, 0.3125, 0.5625, 0.8750, 0.1250, 0.0000,\n",
       "           0.0000, 0.0000, 0.5000, 0.8750, 0.7500, 0.1875, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[1.]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1,image2,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), 'checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
